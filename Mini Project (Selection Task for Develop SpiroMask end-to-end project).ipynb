{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1> <u>Aim</u> - </h1>\n",
    "    <h2> To obtain breathing information from audio captured using microphone placed inside an Cloth mask. </h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> You can also refer this <a href=\"https://youtu.be/49G2uIdIseg\"> Youtube video made for audio-visual explaination of this project. </a> </p>\n",
    "\n",
    "<p> Note - For some unknown reasons, embedded image urls are not getting rendered inside notebook even after trying some troubleshooting options. Thus, I have kept url's HTML part as it is which you can access either by clicking on it or by exporting this notebook in HTML file format and inspecting the image part with the help of web browser. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div>\n",
    "<h2> <u>Apparatus Used</u> - </h2>\n",
    "    <ol> \n",
    "        <li>Cotton Mask</li>\n",
    "        <li>Boat BassHeads 100 Wired Earphone</li>\n",
    "        <li>Samsung Galaxy F12 Smartphone</li>\n",
    "        <li> HP 15db0186au Laptop </li>\n",
    "        <li>Cellotape, scissor</li>\n",
    "    </ol>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <p> <font size=\"4\"> <b><u>Softwares Used</u> - </b></font> Audacity, Samsung Voice Recorder app </p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <u>Procedure</u> - </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 1) Stick Microphone part of earphone inside the mask at appropriate position (as shown in diagram) </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 2) Connect earphone with your smartphone and open voice recorder app, note down the sample rate of audio being recorded. Then, start recording the audio of your breath. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 3) Record audio for around 30 seconds which will include total 4 breathing cycles ( 2 Tidal breathing + 2 Forced breathing). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 4) Move that recorded audio file to PC and import that audio file in Audacity.An graph of Intensity v/s. time will be shown on home screen.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 5) Check for any pattern observed. Then, filter high frequency ranges and check whether there is any change in pattern of graph. Note when you obtain the same. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 6) Note the frequency range where any breathing information is present. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <u>Observation and discussions</u> - </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 1) Things we observe from graph (Amplitude v/s. time) obtained after importing the audio file to Audacity is the visible difference between amplitude of audio signal during inhalation and exhalation of air. <br><br>\n",
    "    2) Second thing we see is the audio signal's amplitude is high during forced breathing as compared to tidal breathing. This observation is due to low intake of air during tidal breathing as compared to forced breathing. </p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/file/d/1hv8sWkm45oSov1EwOyJQ6d2W_8t7ao_H/view?usp=sharing\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 3) To know more differnces between this two types of breathing and extract more information from it. Now, I have used Low Pass Filter (present in Audacity app) and first, I set the maximum frequency limit of 1 kHz. After doing so, I was able to observe that </p> \n",
    "<p> i) Inhalation audio signal of tidal breathing is now almost invisible (even after checking Logarithmic Amplitude (in dB.) vs time graph).<br>\n",
    "    ii) Irregular variation of Inhalation audio signal in forced breathing part. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/file/d/1TYG86f3cOcJcMl_KhNZx0XjtYD5h7Gwk/view?usp=sharing\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 4) As mentioned in research paper, we can obtain detailed breathing information from audio signal of tidal breathing lying in the range of 50 Hz. to 500 Hz. So, I changed the maximum frequency limit from 1kHz. to 150Hz to check whether I am able to do so. After changing the maximum limit, I was able to observe that </p>\n",
    "\n",
    "<p> i) Graph of Inhalation (be it from tidal or forced breathing) became invisible. <br>\n",
    "    ii) Variation of audio signals during exhalation cycle was increased, as seen in image attached below. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/file/d/1pLywxAVAEznXi0w2y3y5NtW_gDDTcFJi/view?usp=sharing\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <u>Conclusion</u> - </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Thus, after looking into graphs of amplitude v/s time of the audio signals, we can detect when the person inhaled and exhaled the air (from the very 1st graph itself), also, with the help of the graph obtained after using low pass filter with maximum frequency limit of 150Hz. and data/methodologies shown in research paper, we can even find more in-detailed breathing information which can help us to determine any lung ailments is thewhich concludes this experiment. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
